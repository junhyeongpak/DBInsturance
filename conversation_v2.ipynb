{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import langgraph\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "json_path = r\"C:/Users/Owner/Desktop/invest portfolio/10K_reports_summary.json\"\n",
    "file_path = \"C:/Users/Owner/Desktop/invest portfolio/dow_30_news.csv\"\n",
    "news_df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Owner/Desktop/invest portfolio/10K_reports_summary.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21morganize_data_by_year\u001b[39m(data):\n",
      "File \u001b[0;32m~/workplace/DBá„‡á…©á„’á…¥á†·á„€á…³á†·á„‹á…²á†¼á„€á…©á†¼á„†á…©á„Œá…¥á†«/venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Owner/Desktop/invest portfolio/10K_reports_summary.json'"
     ]
    }
   ],
   "source": [
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def organize_data_by_year(data):\n",
    "    company_data = {}\n",
    "    for report in data:\n",
    "        file_name = report[\"file_name\"]\n",
    "        year = \"2023\" if \"2023\" in file_name else \"2024\"\n",
    "        company_name = file_name.replace(\"_2023\", \"\").replace(\"_2024\", \"\").replace(\".pdf\", \"\")\n",
    "\n",
    "        if company_name not in company_data:\n",
    "            company_data[company_name] = {}\n",
    "        \n",
    "        summary = report[\"summary\"]\n",
    "        \n",
    "        if isinstance(summary, str):\n",
    "            try:\n",
    "                summary = json.loads(summary)\n",
    "            except json.JSONDecodeError:\n",
    "                summary = {}  \n",
    "        \n",
    "        company_data[company_name][year] = summary\n",
    "\n",
    "    return company_data\n",
    "\n",
    "def translate_to_korean(text: str):\n",
    "    \"\"\"LLMì„ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­\"\"\"\n",
    "    translation_prompt = f\"\"\"\n",
    "    ë‹¤ìŒ íˆ¬ì ê²¬í•´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”.  \n",
    "    ê¸ˆìœµ ìš©ì–´ëŠ” ê°€ëŠ¥í•œ í•œ ì›ë˜ ì˜ë¯¸ë¥¼ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "    **ë²ˆì—­í•  ë‚´ìš©:**  \n",
    "    {text}\n",
    "\n",
    "    **ë²ˆì—­ ê²°ê³¼:**  \n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=translation_prompt)])\n",
    "    return response.content.strip()\n",
    "\n",
    "company_data = organize_data_by_year(data)\n",
    "\n",
    "file_path = \"C:/Users/Owner/Desktop/invest portfolio/dow_30_news.csv\"\n",
    "news_df = pd.read_csv(file_path)\n",
    "\n",
    "# OpenAI LLM ì„¤ì • (ë³€ê²½ ê¸ˆì§€)\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "class InvestmentState(TypedDict):\n",
    "    views: str\n",
    "    prev_views: str \n",
    "    iteration: int\n",
    "\n",
    "\n",
    "# **ğŸ“Œ íˆ¬ì ê²¬í•´ ì´ˆê¸° ìƒì„± í•¨ìˆ˜ (JSON ë°ì´í„° ê¸°ë°˜)**\n",
    "def generate_initial_views(state: InvestmentState):\n",
    "    context = \"\"\n",
    "    for company, years in company_data.items():\n",
    "        context += f\"\\nğŸ“Œ {company}\\n\"\n",
    "        for year, summary in years.items():\n",
    "            context += f\"ğŸ”¹ {year}ë…„ ë°ì´í„°:\\n\"\n",
    "            context += f\"- **Business Overview**: {summary.get('Business Overview', 'N/A')}\\n\"\n",
    "            context += f\"- **Key Risk Factors**: {summary.get('Key Risk Factors', 'N/A')}\\n\"\n",
    "            context += f\"- **Financial Summary**: {summary.get('Financial Summary', 'N/A')}\\n\"\n",
    "            context += f\"- **Management Insights**: {summary.get('Management Insights', 'N/A')}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a financial analyst specializing in Black-Litterman model-based investment insights.\n",
    "    Based on the summarized 10-K reports from 2023 and 2024, generate **max ten investment viewpoints** \n",
    "    using a comparative analysis of companies and their financial performance.\n",
    "\n",
    "    **Company Data:**\n",
    "    {context}\n",
    "\n",
    "    **Instructions:**\n",
    "    - Generate **max ten investment viewpoints** that must **always include specific companies**.\n",
    "    - Each viewpoint **must contain an expected return percentage change (increase or decrease) and which company is**.\n",
    "    - The expected return change **must be between 1% and 8%**.\n",
    "    - Ensure that each viewpoint **directly compares two companies** (e.g., \"Microsoft vs. Google\") or **focuses on a single company's expected return change**.\n",
    "    - Use financial trends, key risks, and management insights to justify each viewpoint.\n",
    "\n",
    "    **Output Format:**\n",
    "    - **Viewpoint 1**: ...\n",
    "    - **Viewpoint 2**: ...\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    print(\"\\nğŸ”µ [ì´ˆê¸° íˆ¬ì ê²¬í•´ ìƒì„± ì™„ë£Œ] ğŸ”µ\\n\", response.content)\n",
    "    return {\"views\": response.content, \"agreement_score\": 0, \"iteration\": 0}\n",
    "\n",
    "\n",
    "def sentiment_analysis_agent(state: InvestmentState):\n",
    "    \"\"\"Perform sentiment analysis on news data and update investment insights.\"\"\"\n",
    "\n",
    "    dow30_ticker_mapping = {\n",
    "        \"Apple\": \"AAPL\", \"Amgen\": \"AMGN\", \"Amazon\": \"AMZN\", \"Cisco\": \"CSCO\", \"Microsoft\": \"MSFT\", \"NVIDIA\": \"NVDA\",\n",
    "        \"American Express\": \"AXP\", \"Boeing\": \"BA\", \"Caterpillar\": \"CAT\", \"Salesforce\": \"CRM\", \"Chevron\": \"CVX\",\n",
    "        \"Disney\": \"DIS\", \"Goldman Sachs\": \"GS\", \"Home Depot\": \"HD\", \"Honeywell\": \"HON\", \"IBM\": \"IBM\",\n",
    "        \"Johnson & Johnson\": \"JNJ\", \"JPMorgan Chase\": \"JPM\", \"Coca-Cola\": \"KO\", \"McDonald's\": \"MCD\", \"3M\": \"MMM\",\n",
    "        \"Merck\": \"MRK\", \"Nike\": \"NKE\", \"Procter & Gamble\": \"PG\", \"Sherwin-Williams\": \"SHW\", \"Travelers\": \"TRV\",\n",
    "        \"UnitedHealth\": \"UNH\", \"Visa\": \"V\", \"Verizon\": \"VZ\", \"Walmart\": \"WMT\"\n",
    "    }\n",
    "\n",
    "    mentioned_tickers = [ticker for company, ticker in dow30_ticker_mapping.items() if company in state[\"views\"]]\n",
    "    if not mentioned_tickers:\n",
    "        print(\"âš ï¸ No relevant stocks found for sentiment analysis.\")\n",
    "        return state\n",
    "\n",
    "    filtered_news_df = news_df[news_df[\"ticker\"].isin(mentioned_tickers)].dropna(subset=[\"summary\"])\n",
    "    filtered_news_df[\"summary\"] = filtered_news_df[\"summary\"].fillna(\"\").astype(str)\n",
    "\n",
    "    if filtered_news_df.empty:\n",
    "        print(\"âš ï¸ No relevant news articles found.\")\n",
    "        return state\n",
    "\n",
    "    filtered_news_df = filtered_news_df.sort_values(by=\"datetime\", ascending=False)\n",
    "\n",
    "    summarized_news = {}\n",
    "    for ticker in mentioned_tickers:\n",
    "        subset = filtered_news_df[filtered_news_df[\"ticker\"] == ticker]\n",
    "        if subset.empty:\n",
    "            continue  \n",
    "        num_articles = random.randint(3, min(5, len(subset)))  \n",
    "        selected_articles = subset.sample(n=num_articles, random_state=random.randint(1, 1000))[\"summary\"].tolist()\n",
    "        summarized_news[ticker] = \" \".join(selected_articles)\n",
    "\n",
    "    if not summarized_news:\n",
    "        print(\"âš ï¸ No sampled news articles found.\")\n",
    "        return state\n",
    "\n",
    "    sentiment_prompt = f\"\"\"\n",
    "    Analyze the sentiment of the following news summaries and classify them as Positive, Negative, or Neutral.\n",
    "\n",
    "    **News Summaries:**\n",
    "    {summarized_news}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke([HumanMessage(content=sentiment_prompt)])\n",
    "    sentiment_results = response.content.strip()\n",
    "\n",
    "    print(\"\\nğŸŸ¡ [Sentiment Analysis Results] ğŸŸ¡\")\n",
    "    print(sentiment_results)\n",
    "\n",
    "    adjustment_prompt = f\"\"\"\n",
    "    Modify the following investment viewpoints based on the sentiment analysis results.\n",
    "\n",
    "    **Current Investment Viewpoints:**\n",
    "    {state[\"views\"]}\n",
    "\n",
    "    **Sentiment Analysis Results:**\n",
    "    {sentiment_results}\n",
    "\n",
    "    **Instructions:**\n",
    "    - Adjust expected return percentages based on sentiment.\n",
    "    - Ensure that the updated viewpoints remain within the 1% to 8% range.\n",
    "    \"\"\"\n",
    "\n",
    "    adjusted_response = llm.invoke([HumanMessage(content=adjustment_prompt)])\n",
    "    adjusted_views = adjusted_response.content.strip()\n",
    "\n",
    "    print(\"\\nğŸŸ¡ [Updated Investment Views after Sentiment Analysis] ğŸŸ¡\")\n",
    "    print(adjusted_views)\n",
    "\n",
    "    return {\n",
    "        \"views\": adjusted_views,\n",
    "        \"prev_views\": state[\"views\"],\n",
    "        \"iteration\": state[\"iteration\"] + 1\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def financial_analysis_agent(state: InvestmentState):\n",
    "    \"\"\"ì¬ë¬´ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ê°ì„± ë¶„ì„ ê¸°ëŒ€ ìˆ˜ìµë¥ ì´ ì ì ˆí•œì§€ GPT APIë¥¼ í™œìš©í•´ ê²€ì¦í•˜ê³  ì¡°ì •í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    dow30_ticker_mapping = {\n",
    "        \"Apple\": \"AAPL\", \"Amgen\": \"AMGN\", \"Amazon\": \"AMZN\", \"Cisco\": \"CSCO\", \"Microsoft\": \"MSFT\", \"NVIDIA\": \"NVDA\",\n",
    "        \"American Express\": \"AXP\", \"Boeing\": \"BA\", \"Caterpillar\": \"CAT\", \"Salesforce\": \"CRM\", \"Chevron\": \"CVX\",\n",
    "        \"Disney\": \"DIS\", \"Goldman Sachs\": \"GS\", \"Home Depot\": \"HD\", \"Honeywell\": \"HON\", \"IBM\": \"IBM\",\n",
    "        \"Johnson & Johnson\": \"JNJ\", \"JPMorgan Chase\": \"JPM\", \"Coca-Cola\": \"KO\", \"McDonald's\": \"MCD\", \"3M\": \"MMM\",\n",
    "        \"Merck\": \"MRK\", \"Nike\": \"NKE\", \"Procter & Gamble\": \"PG\", \"Sherwin-Williams\": \"SHW\", \"Travelers\": \"TRV\",\n",
    "        \"UnitedHealth\": \"UNH\", \"Visa\": \"V\", \"Verizon\": \"VZ\", \"Walmart\": \"WMT\"\n",
    "    }\n",
    "\n",
    "    financial_df = pd.read_csv(\"/Users/wnsgud/workplace/DBë³´í—˜ê¸ˆìœµê³µëª¨ì „/financial_ratios/All_Financial_Ratios.csv\")\n",
    "\n",
    "    # ê¸°ì¡´ íˆ¬ì ê²¬í•´ì—ì„œ ì¢…ëª©ëª…ê³¼ ê¸°ëŒ€ ìˆ˜ìµë¥  ì¶”ì¶œ\n",
    "    viewpoints = state[\"views\"].split(\"\\n\")\n",
    "    adjusted_viewpoints = []\n",
    "    \n",
    "    for viewpoint in viewpoints:\n",
    "        match = re.search(r'\\*\\*(.*?)\\*\\*.*?([+-]?\\d+(?:\\.\\d+)?)%', viewpoint)\n",
    "        if not match:\n",
    "            adjusted_viewpoints.append(viewpoint)\n",
    "            continue\n",
    "        \n",
    "        company, expected_return = match.groups()\n",
    "        expected_return = float(expected_return)\n",
    "        ticker = dow30_ticker_mapping.get(company)\n",
    "        \n",
    "        if not ticker:\n",
    "            adjusted_viewpoints.append(viewpoint)\n",
    "            continue\n",
    "        \n",
    "        # í•´ë‹¹ ì¢…ëª©ê³¼ ì—°ë„ì˜ ì¬ë¬´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
    "        latest_year = max(financial_df[\"ì—°ë„\"].astype(str).unique())\n",
    "        company_financials = financial_df[(financial_df[\"ì¢…ëª©ëª…\"] == ticker) & (financial_df[\"ì—°ë„\"].astype(str) == latest_year)]\n",
    "        \n",
    "        if company_financials.empty:\n",
    "            adjusted_viewpoints.append(viewpoint)\n",
    "            continue\n",
    "        \n",
    "        # ëª¨ë“  ì¬ë¬´ ì§€í‘œ ê°€ì ¸ì˜¤ê¸°\n",
    "        financial_metrics = company_financials.iloc[0].to_dict()\n",
    "        \n",
    "        # GPT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ëŒ€ ìˆ˜ìµë¥  ì¡°ì •\n",
    "        prompt = f\"\"\"\n",
    "        Given the financial indicators of {company}, adjust the expected return accordingly.\n",
    "        \n",
    "        **Financial Indicators:**\n",
    "        Growth: {financial_metrics.get(\"ì´ìì‚° ì¦ê°€ìœ¨\", \"N/A\")}, {financial_metrics.get(\"ìœ í˜•ìì‚° ì¦ê°€ìœ¨\", \"N/A\")}, {financial_metrics.get(\"ë§¤ì¶œì•¡ ì¦ê°€ìœ¨\", \"N/A\")}\n",
    "        Profitability: {financial_metrics.get(\"ë§¤ì¶œì•¡ ì˜ì—…ì´ìµë¥ \", \"N/A\")}, {financial_metrics.get(\"ë§¤ì¶œì•¡ ìˆœì´ìµë¥ \", \"N/A\")}, {financial_metrics.get(\"ì´ìì‚° ì˜ì—…ì´ìµë¥ \", \"N/A\")}, {financial_metrics.get(\"ì´ìì‚° ìˆœì´ìµë¥ \", \"N/A\")}, {financial_metrics.get(\"ì˜ì—…ì´ìµ ì´ìë³´ìƒë¹„ìœ¨\", \"N/A\")}, {financial_metrics.get(\"EBITDAëŒ€ ë§¤ì¶œì•¡\", \"N/A\")}\n",
    "        Liquidity: {financial_metrics.get(\"ìœ ë™ë¹„ìœ¨\", \"N/A\")}, {financial_metrics.get(\"ë‹¹ì¢Œë¹„ìœ¨\", \"N/A\")}, {financial_metrics.get(\"ë§¤ì¶œì±„ê¶Œ/ë§¤ì…ì±„ë¬´ë¹„ìœ¨\", \"N/A\")}\n",
    "        Stability: {financial_metrics.get(\"ë¶€ì±„ë¹„ìœ¨\", \"N/A\")}, {financial_metrics.get(\"ìœ ë™ë¶€ì±„ë¹„ìœ¨\", \"N/A\")}, {financial_metrics.get(\"ì°¨ì…ê¸ˆì˜ì¡´ë„\", \"N/A\")}\n",
    "        Efficiency: {financial_metrics.get(\"ì´ìì‚°íšŒì „ìœ¨\", \"N/A\")}, {financial_metrics.get(\"ì¬ê³ ìì‚°íšŒì „ìœ¨\", \"N/A\")}, {financial_metrics.get(\"ë§¤ì¶œì±„ê¶ŒíšŒì „ìœ¨\", \"N/A\")}\n",
    "        \n",
    "        Adjust the expected return ({expected_return}%) based on the above indicators.\n",
    "        \n",
    "        Return the adjusted expected return as a single numerical value followed by a percentage sign.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        financial_expected_return = response.content.strip()\n",
    "        \n",
    "        # ê¸°ëŒ€ ìˆ˜ìµë¥ ì„ 1% ~ 8% ë²”ìœ„ë¡œ ì¡°ì •\n",
    "        try:\n",
    "            financial_expected_return = float(financial_expected_return.replace(\"%\", \"\"))\n",
    "            financial_expected_return = max(1, min(8, financial_expected_return))\n",
    "        except ValueError:\n",
    "            financial_expected_return = expected_return\n",
    "        \n",
    "        if abs(expected_return - financial_expected_return) > 2:\n",
    "            viewpoint = re.sub(r'([+-]?\\d+(?:\\.\\d+)?)%', f\"{financial_expected_return:.1f}%\", viewpoint)\n",
    "        \n",
    "        adjusted_viewpoints.append(viewpoint)\n",
    "    \n",
    "    updated_views = \"\\n\".join(adjusted_viewpoints)\n",
    "    \n",
    "    print(\"\\nğŸ”µ [ì¬ë¬´ ë°ì´í„° ê²€ì¦ ë° ì¡°ì • í›„ íˆ¬ì ê²¬í•´] ğŸ”µ\")\n",
    "    print(updated_views)\n",
    "    \n",
    "    return {\n",
    "        \"views\": updated_views,\n",
    "        \"prev_views\": state[\"views\"],\n",
    "        \"iteration\": state[\"iteration\"] + 1\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def check_convergence(state: InvestmentState):\n",
    "    \"\"\"ê°ì„± ë¶„ì„ê³¼ ì¬ë¬´ ë¶„ì„ì´ ì¼ì • ìˆ˜ì¤€ê¹Œì§€ ì¼ì¹˜í•˜ë©´ ì¢…ë£Œ\"\"\"\n",
    "    if state[\"iteration\"] >= 5:\n",
    "        return END\n",
    "    return \"sentiment_analysis\"\n",
    "\n",
    "\n",
    "# **ğŸ“Œ LangGraph ì„¤ì •**\n",
    "workflow = StateGraph(InvestmentState)\n",
    "\n",
    "workflow.add_node(\"generate_views\", generate_initial_views)\n",
    "workflow.add_edge(START, \"generate_views\")\n",
    "\n",
    "workflow.add_node(\"sentiment_analysis\", sentiment_analysis_agent)\n",
    "workflow.add_node(\"financial_analysis\", financial_analysis_agent)\n",
    "\n",
    "workflow.add_edge(\"generate_views\", \"sentiment_analysis\")\n",
    "workflow.add_edge(\"sentiment_analysis\", \"financial_analysis\")\n",
    "workflow.add_conditional_edges(\"financial_analysis\", check_convergence)\n",
    "\n",
    "# **ğŸ“Œ ê·¸ë˜í”„ ì‹¤í–‰**\n",
    "app = workflow.compile()\n",
    "result = app.invoke({\"views\": \"\", \"prev_views\": \"\", \"agreement_score\": 5, \"iteration\": 0})\n",
    "\n",
    "print(\"\\nâœ… **ìµœì¢… ë³´ì™„ëœ íˆ¬ì ê²¬í•´:**\\n\")\n",
    "print(result[\"views\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
