{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import langgraph\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "json_path = r\"C:/Users/Owner/Desktop/invest portfolio/10K_reports_summary.json\"\n",
    "file_path = \"C:/Users/Owner/Desktop/invest portfolio/dow_30_news.csv\"\n",
    "news_df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Owner/Desktop/invest portfolio/10K_reports_summary.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21morganize_data_by_year\u001b[39m(data):\n",
      "File \u001b[0;32m~/workplace/DB보험금융공모전/venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Owner/Desktop/invest portfolio/10K_reports_summary.json'"
     ]
    }
   ],
   "source": [
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def organize_data_by_year(data):\n",
    "    company_data = {}\n",
    "    for report in data:\n",
    "        file_name = report[\"file_name\"]\n",
    "        year = \"2023\" if \"2023\" in file_name else \"2024\"\n",
    "        company_name = file_name.replace(\"_2023\", \"\").replace(\"_2024\", \"\").replace(\".pdf\", \"\")\n",
    "\n",
    "        if company_name not in company_data:\n",
    "            company_data[company_name] = {}\n",
    "        \n",
    "        summary = report[\"summary\"]\n",
    "        \n",
    "        if isinstance(summary, str):\n",
    "            try:\n",
    "                summary = json.loads(summary)\n",
    "            except json.JSONDecodeError:\n",
    "                summary = {}  \n",
    "        \n",
    "        company_data[company_name][year] = summary\n",
    "\n",
    "    return company_data\n",
    "\n",
    "def translate_to_korean(text: str):\n",
    "    \"\"\"LLM을 사용하여 주어진 텍스트를 한국어로 번역\"\"\"\n",
    "    translation_prompt = f\"\"\"\n",
    "    다음 투자 견해를 한국어로 번역하세요.  \n",
    "    금융 용어는 가능한 한 원래 의미를 유지해야 합니다.\n",
    "\n",
    "    **번역할 내용:**  \n",
    "    {text}\n",
    "\n",
    "    **번역 결과:**  \n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=translation_prompt)])\n",
    "    return response.content.strip()\n",
    "\n",
    "company_data = organize_data_by_year(data)\n",
    "\n",
    "file_path = \"C:/Users/Owner/Desktop/invest portfolio/dow_30_news.csv\"\n",
    "news_df = pd.read_csv(file_path)\n",
    "\n",
    "# OpenAI LLM 설정 (변경 금지)\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "class InvestmentState(TypedDict):\n",
    "    views: str\n",
    "    prev_views: str \n",
    "    iteration: int\n",
    "\n",
    "\n",
    "# **📌 투자 견해 초기 생성 함수 (JSON 데이터 기반)**\n",
    "def generate_initial_views(state: InvestmentState):\n",
    "    context = \"\"\n",
    "    for company, years in company_data.items():\n",
    "        context += f\"\\n📌 {company}\\n\"\n",
    "        for year, summary in years.items():\n",
    "            context += f\"🔹 {year}년 데이터:\\n\"\n",
    "            context += f\"- **Business Overview**: {summary.get('Business Overview', 'N/A')}\\n\"\n",
    "            context += f\"- **Key Risk Factors**: {summary.get('Key Risk Factors', 'N/A')}\\n\"\n",
    "            context += f\"- **Financial Summary**: {summary.get('Financial Summary', 'N/A')}\\n\"\n",
    "            context += f\"- **Management Insights**: {summary.get('Management Insights', 'N/A')}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a financial analyst specializing in Black-Litterman model-based investment insights.\n",
    "    Based on the summarized 10-K reports from 2023 and 2024, generate **max ten investment viewpoints** \n",
    "    using a comparative analysis of companies and their financial performance.\n",
    "\n",
    "    **Company Data:**\n",
    "    {context}\n",
    "\n",
    "    **Instructions:**\n",
    "    - Generate **max ten investment viewpoints** that must **always include specific companies**.\n",
    "    - Each viewpoint **must contain an expected return percentage change (increase or decrease) and which company is**.\n",
    "    - The expected return change **must be between 1% and 8%**.\n",
    "    - Ensure that each viewpoint **directly compares two companies** (e.g., \"Microsoft vs. Google\") or **focuses on a single company's expected return change**.\n",
    "    - Use financial trends, key risks, and management insights to justify each viewpoint.\n",
    "\n",
    "    **Output Format:**\n",
    "    - **Viewpoint 1**: ...\n",
    "    - **Viewpoint 2**: ...\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    print(\"\\n🔵 [초기 투자 견해 생성 완료] 🔵\\n\", response.content)\n",
    "    return {\"views\": response.content, \"agreement_score\": 0, \"iteration\": 0}\n",
    "\n",
    "\n",
    "def sentiment_analysis_agent(state: InvestmentState):\n",
    "    \"\"\"Perform sentiment analysis on news data and update investment insights.\"\"\"\n",
    "\n",
    "    dow30_ticker_mapping = {\n",
    "        \"Apple\": \"AAPL\", \"Amgen\": \"AMGN\", \"Amazon\": \"AMZN\", \"Cisco\": \"CSCO\", \"Microsoft\": \"MSFT\", \"NVIDIA\": \"NVDA\",\n",
    "        \"American Express\": \"AXP\", \"Boeing\": \"BA\", \"Caterpillar\": \"CAT\", \"Salesforce\": \"CRM\", \"Chevron\": \"CVX\",\n",
    "        \"Disney\": \"DIS\", \"Goldman Sachs\": \"GS\", \"Home Depot\": \"HD\", \"Honeywell\": \"HON\", \"IBM\": \"IBM\",\n",
    "        \"Johnson & Johnson\": \"JNJ\", \"JPMorgan Chase\": \"JPM\", \"Coca-Cola\": \"KO\", \"McDonald's\": \"MCD\", \"3M\": \"MMM\",\n",
    "        \"Merck\": \"MRK\", \"Nike\": \"NKE\", \"Procter & Gamble\": \"PG\", \"Sherwin-Williams\": \"SHW\", \"Travelers\": \"TRV\",\n",
    "        \"UnitedHealth\": \"UNH\", \"Visa\": \"V\", \"Verizon\": \"VZ\", \"Walmart\": \"WMT\"\n",
    "    }\n",
    "\n",
    "    mentioned_tickers = [ticker for company, ticker in dow30_ticker_mapping.items() if company in state[\"views\"]]\n",
    "    if not mentioned_tickers:\n",
    "        print(\"⚠️ No relevant stocks found for sentiment analysis.\")\n",
    "        return state\n",
    "\n",
    "    filtered_news_df = news_df[news_df[\"ticker\"].isin(mentioned_tickers)].dropna(subset=[\"summary\"])\n",
    "    filtered_news_df[\"summary\"] = filtered_news_df[\"summary\"].fillna(\"\").astype(str)\n",
    "\n",
    "    if filtered_news_df.empty:\n",
    "        print(\"⚠️ No relevant news articles found.\")\n",
    "        return state\n",
    "\n",
    "    filtered_news_df = filtered_news_df.sort_values(by=\"datetime\", ascending=False)\n",
    "\n",
    "    summarized_news = {}\n",
    "    for ticker in mentioned_tickers:\n",
    "        subset = filtered_news_df[filtered_news_df[\"ticker\"] == ticker]\n",
    "        if subset.empty:\n",
    "            continue  \n",
    "        num_articles = random.randint(3, min(5, len(subset)))  \n",
    "        selected_articles = subset.sample(n=num_articles, random_state=random.randint(1, 1000))[\"summary\"].tolist()\n",
    "        summarized_news[ticker] = \" \".join(selected_articles)\n",
    "\n",
    "    if not summarized_news:\n",
    "        print(\"⚠️ No sampled news articles found.\")\n",
    "        return state\n",
    "\n",
    "    sentiment_prompt = f\"\"\"\n",
    "    Analyze the sentiment of the following news summaries and classify them as Positive, Negative, or Neutral.\n",
    "\n",
    "    **News Summaries:**\n",
    "    {summarized_news}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke([HumanMessage(content=sentiment_prompt)])\n",
    "    sentiment_results = response.content.strip()\n",
    "\n",
    "    print(\"\\n🟡 [Sentiment Analysis Results] 🟡\")\n",
    "    print(sentiment_results)\n",
    "\n",
    "    adjustment_prompt = f\"\"\"\n",
    "    Modify the following investment viewpoints based on the sentiment analysis results.\n",
    "\n",
    "    **Current Investment Viewpoints:**\n",
    "    {state[\"views\"]}\n",
    "\n",
    "    **Sentiment Analysis Results:**\n",
    "    {sentiment_results}\n",
    "\n",
    "    **Instructions:**\n",
    "    - Adjust expected return percentages based on sentiment.\n",
    "    - Ensure that the updated viewpoints remain within the 1% to 8% range.\n",
    "    \"\"\"\n",
    "\n",
    "    adjusted_response = llm.invoke([HumanMessage(content=adjustment_prompt)])\n",
    "    adjusted_views = adjusted_response.content.strip()\n",
    "\n",
    "    print(\"\\n🟡 [Updated Investment Views after Sentiment Analysis] 🟡\")\n",
    "    print(adjusted_views)\n",
    "\n",
    "    return {\n",
    "        \"views\": adjusted_views,\n",
    "        \"prev_views\": state[\"views\"],\n",
    "        \"iteration\": state[\"iteration\"] + 1\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def financial_analysis_agent(state: InvestmentState):\n",
    "    \"\"\"재무 데이터 기반으로 감성 분석 기대 수익률이 적절한지 GPT API를 활용해 검증하고 조정하는 함수\"\"\"\n",
    "    \n",
    "    dow30_ticker_mapping = {\n",
    "        \"Apple\": \"AAPL\", \"Amgen\": \"AMGN\", \"Amazon\": \"AMZN\", \"Cisco\": \"CSCO\", \"Microsoft\": \"MSFT\", \"NVIDIA\": \"NVDA\",\n",
    "        \"American Express\": \"AXP\", \"Boeing\": \"BA\", \"Caterpillar\": \"CAT\", \"Salesforce\": \"CRM\", \"Chevron\": \"CVX\",\n",
    "        \"Disney\": \"DIS\", \"Goldman Sachs\": \"GS\", \"Home Depot\": \"HD\", \"Honeywell\": \"HON\", \"IBM\": \"IBM\",\n",
    "        \"Johnson & Johnson\": \"JNJ\", \"JPMorgan Chase\": \"JPM\", \"Coca-Cola\": \"KO\", \"McDonald's\": \"MCD\", \"3M\": \"MMM\",\n",
    "        \"Merck\": \"MRK\", \"Nike\": \"NKE\", \"Procter & Gamble\": \"PG\", \"Sherwin-Williams\": \"SHW\", \"Travelers\": \"TRV\",\n",
    "        \"UnitedHealth\": \"UNH\", \"Visa\": \"V\", \"Verizon\": \"VZ\", \"Walmart\": \"WMT\"\n",
    "    }\n",
    "\n",
    "    financial_df = pd.read_csv(\"/Users/wnsgud/workplace/DB보험금융공모전/financial_ratios/All_Financial_Ratios.csv\")\n",
    "\n",
    "    # 기존 투자 견해에서 종목명과 기대 수익률 추출\n",
    "    viewpoints = state[\"views\"].split(\"\\n\")\n",
    "    adjusted_viewpoints = []\n",
    "    \n",
    "    for viewpoint in viewpoints:\n",
    "        match = re.search(r'\\*\\*(.*?)\\*\\*.*?([+-]?\\d+(?:\\.\\d+)?)%', viewpoint)\n",
    "        if not match:\n",
    "            adjusted_viewpoints.append(viewpoint)\n",
    "            continue\n",
    "        \n",
    "        company, expected_return = match.groups()\n",
    "        expected_return = float(expected_return)\n",
    "        ticker = dow30_ticker_mapping.get(company)\n",
    "        \n",
    "        if not ticker:\n",
    "            adjusted_viewpoints.append(viewpoint)\n",
    "            continue\n",
    "        \n",
    "        # 해당 종목과 연도의 재무 데이터 가져오기\n",
    "        latest_year = max(financial_df[\"연도\"].astype(str).unique())\n",
    "        company_financials = financial_df[(financial_df[\"종목명\"] == ticker) & (financial_df[\"연도\"].astype(str) == latest_year)]\n",
    "        \n",
    "        if company_financials.empty:\n",
    "            adjusted_viewpoints.append(viewpoint)\n",
    "            continue\n",
    "        \n",
    "        # 모든 재무 지표 가져오기\n",
    "        financial_metrics = company_financials.iloc[0].to_dict()\n",
    "        \n",
    "        # GPT API를 사용하여 기대 수익률 조정\n",
    "        prompt = f\"\"\"\n",
    "        Given the financial indicators of {company}, adjust the expected return accordingly.\n",
    "        \n",
    "        **Financial Indicators:**\n",
    "        Growth: {financial_metrics.get(\"총자산 증가율\", \"N/A\")}, {financial_metrics.get(\"유형자산 증가율\", \"N/A\")}, {financial_metrics.get(\"매출액 증가율\", \"N/A\")}\n",
    "        Profitability: {financial_metrics.get(\"매출액 영업이익률\", \"N/A\")}, {financial_metrics.get(\"매출액 순이익률\", \"N/A\")}, {financial_metrics.get(\"총자산 영업이익률\", \"N/A\")}, {financial_metrics.get(\"총자산 순이익률\", \"N/A\")}, {financial_metrics.get(\"영업이익 이자보상비율\", \"N/A\")}, {financial_metrics.get(\"EBITDA대 매출액\", \"N/A\")}\n",
    "        Liquidity: {financial_metrics.get(\"유동비율\", \"N/A\")}, {financial_metrics.get(\"당좌비율\", \"N/A\")}, {financial_metrics.get(\"매출채권/매입채무비율\", \"N/A\")}\n",
    "        Stability: {financial_metrics.get(\"부채비율\", \"N/A\")}, {financial_metrics.get(\"유동부채비율\", \"N/A\")}, {financial_metrics.get(\"차입금의존도\", \"N/A\")}\n",
    "        Efficiency: {financial_metrics.get(\"총자산회전율\", \"N/A\")}, {financial_metrics.get(\"재고자산회전율\", \"N/A\")}, {financial_metrics.get(\"매출채권회전율\", \"N/A\")}\n",
    "        \n",
    "        Adjust the expected return ({expected_return}%) based on the above indicators.\n",
    "        \n",
    "        Return the adjusted expected return as a single numerical value followed by a percentage sign.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        financial_expected_return = response.content.strip()\n",
    "        \n",
    "        # 기대 수익률을 1% ~ 8% 범위로 조정\n",
    "        try:\n",
    "            financial_expected_return = float(financial_expected_return.replace(\"%\", \"\"))\n",
    "            financial_expected_return = max(1, min(8, financial_expected_return))\n",
    "        except ValueError:\n",
    "            financial_expected_return = expected_return\n",
    "        \n",
    "        if abs(expected_return - financial_expected_return) > 2:\n",
    "            viewpoint = re.sub(r'([+-]?\\d+(?:\\.\\d+)?)%', f\"{financial_expected_return:.1f}%\", viewpoint)\n",
    "        \n",
    "        adjusted_viewpoints.append(viewpoint)\n",
    "    \n",
    "    updated_views = \"\\n\".join(adjusted_viewpoints)\n",
    "    \n",
    "    print(\"\\n🔵 [재무 데이터 검증 및 조정 후 투자 견해] 🔵\")\n",
    "    print(updated_views)\n",
    "    \n",
    "    return {\n",
    "        \"views\": updated_views,\n",
    "        \"prev_views\": state[\"views\"],\n",
    "        \"iteration\": state[\"iteration\"] + 1\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def check_convergence(state: InvestmentState):\n",
    "    \"\"\"감성 분석과 재무 분석이 일정 수준까지 일치하면 종료\"\"\"\n",
    "    if state[\"iteration\"] >= 5:\n",
    "        return END\n",
    "    return \"sentiment_analysis\"\n",
    "\n",
    "\n",
    "# **📌 LangGraph 설정**\n",
    "workflow = StateGraph(InvestmentState)\n",
    "\n",
    "workflow.add_node(\"generate_views\", generate_initial_views)\n",
    "workflow.add_edge(START, \"generate_views\")\n",
    "\n",
    "workflow.add_node(\"sentiment_analysis\", sentiment_analysis_agent)\n",
    "workflow.add_node(\"financial_analysis\", financial_analysis_agent)\n",
    "\n",
    "workflow.add_edge(\"generate_views\", \"sentiment_analysis\")\n",
    "workflow.add_edge(\"sentiment_analysis\", \"financial_analysis\")\n",
    "workflow.add_conditional_edges(\"financial_analysis\", check_convergence)\n",
    "\n",
    "# **📌 그래프 실행**\n",
    "app = workflow.compile()\n",
    "result = app.invoke({\"views\": \"\", \"prev_views\": \"\", \"agreement_score\": 5, \"iteration\": 0})\n",
    "\n",
    "print(\"\\n✅ **최종 보완된 투자 견해:**\\n\")\n",
    "print(result[\"views\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
